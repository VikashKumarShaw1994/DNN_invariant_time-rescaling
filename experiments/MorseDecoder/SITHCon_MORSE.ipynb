{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf3KhYlVIfNz",
        "outputId": "d0d4c3d3-c753-47c0-fc04-e32439a4d2c6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct 13 01:02:51 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/')"
      ],
      "metadata": {
        "id": "Q1oW5m7LLjHz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1257327-1556-4ab6-c3db-2302f998dad6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-03T01:36:37.390727Z",
          "start_time": "2021-05-03T01:36:37.208757Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BojtTyJHRXN",
        "outputId": "6589bbbd-73c0-4af5-d84d-472981624a24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DNN_invariant_sithcon'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 46 (delta 10), reused 46 (delta 10), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (46/46), 6.26 MiB | 16.56 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "!git clone https://github.com/VikashKumarShaw1994/DNN_invariant_time-rescaling.git DNN_invariant_sithcon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-03T01:36:37.943324Z",
          "start_time": "2021-05-03T01:36:37.391688Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ-T_7LVHRXR",
        "outputId": "d3ed86a9-e8bd-4ea6-80c4-079d6e0d0bc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.cuda.FloatTensor'>\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "sn.set_context(\"poster\")\n",
        "\n",
        "import torch\n",
        "from torch import nn as nn\n",
        "ttype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
        "ctype = torch.cuda.LongTensor if torch.cuda.is_available() else torch.LongTensor\n",
        "print(ttype)\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import gridspec\n",
        "from DNN_invariant_sithcon.SITHCon.sithcon import SITHCon_Layer\n",
        "#from sithcon import SITHCon_Layer, _SITHCon_Core, iSITH\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import itertools\n",
        "from csv import DictWriter\n",
        "import os\n",
        "from os.path import join\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from math import factorial\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-03T01:08:04.831113Z",
          "start_time": "2021-05-03T01:08:04.827482Z"
        },
        "id": "rPhdYwPrHRXT"
      },
      "outputs": [],
      "source": [
        "MORSE_CODE_DICT = { 'A':'.-', 'B':'-...',\n",
        "                    'C':'-.-.', 'D':'-..', 'E':'.',\n",
        "                    'F':'..-.', 'G':'--.', 'H':'....',\n",
        "                    'I':'..', 'J':'.---', 'K':'-.-',\n",
        "                    'L':'.-..', 'M':'--', 'N':'-.',\n",
        "                    'O':'---', 'P':'.--.', 'Q':'--.-',\n",
        "                    'R':'.-.', 'S':'...', 'T':'-',\n",
        "                    'U':'..-', 'V':'...-', 'W':'.--',\n",
        "                    'X':'-..-', 'Y':'-.--', 'Z':'--..',\n",
        "                    '1':'.----', '2':'..---', '3':'...--',\n",
        "                    '4':'....-', '5':'.....', '6':'-....',\n",
        "                    '7':'--...', '8':'---..', '9':'----.',\n",
        "                    '0':'-----', ', ':'--..--', '.':'.-.-.-',\n",
        "                    '?':'..--..', '/':'-..-.', '-':'-....-',\n",
        "                    '(':'-.--.', ')':'-.--.-'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-03T01:08:04.845819Z",
          "start_time": "2021-05-03T01:08:04.831952Z"
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knjD1UwEHRXU",
        "outputId": "00733606-2de1-4d95-aabe-c128b94a0502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 1 1 0 0 0] A\n",
            "[1 1 1 0 1 0 1 0 1 0 0 0] B\n",
            "[1 1 1 0 1 0 1 1 1 0 1 0 0 0] C\n",
            "[1 1 1 0 1 0 1 0 0 0] D\n",
            "[1 0 0 0] E\n",
            "[1 0 1 0 1 1 1 0 1 0 0 0] F\n",
            "[1 1 1 0 1 1 1 0 1 0 0 0] G\n",
            "[1 0 1 0 1 0 1 0 0 0] H\n",
            "[1 0 1 0 0 0] I\n",
            "[1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 0] J\n",
            "[1 1 1 0 1 0 1 1 1 0 0 0] K\n",
            "[1 0 1 1 1 0 1 0 1 0 0 0] L\n",
            "[1 1 1 0 1 1 1 0 0 0] M\n",
            "[1 1 1 0 1 0 0 0] N\n",
            "[1 1 1 0 1 1 1 0 1 1 1 0 0 0] O\n",
            "[1 0 1 1 1 0 1 1 1 0 1 0 0 0] P\n",
            "[1 1 1 0 1 1 1 0 1 0 1 1 1 0 0 0] Q\n",
            "[1 0 1 1 1 0 1 0 0 0] R\n",
            "[1 0 1 0 1 0 0 0] S\n",
            "[1 1 1 0 0 0] T\n",
            "[1 0 1 0 1 1 1 0 0 0] U\n",
            "[1 0 1 0 1 0 1 1 1 0 0 0] V\n",
            "[1 0 1 1 1 0 1 1 1 0 0 0] W\n",
            "[1 1 1 0 1 0 1 0 1 1 1 0 0 0] X\n",
            "[1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0] Y\n",
            "[1 1 1 0 1 1 1 0 1 0 1 0 0 0] Z\n",
            "[1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 0] 1\n",
            "[1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 0] 2\n",
            "[1 0 1 0 1 0 1 1 1 0 1 1 1 0 0 0] 3\n",
            "[1 0 1 0 1 0 1 0 1 1 1 0 0 0] 4\n",
            "[1 0 1 0 1 0 1 0 1 0 0 0] 5\n",
            "[1 1 1 0 1 0 1 0 1 0 1 0 0 0] 6\n",
            "[1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 0] 7\n",
            "[1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 0] 8\n",
            "[1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 0] 9\n",
            "[1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 0] 0\n",
            "[1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 0 0 0] , \n",
            "[1 0 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 0 0 0] .\n",
            "[1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 0] ?\n",
            "[1 1 1 0 1 0 1 0 1 1 1 0 1 0 0 0] /\n",
            "[1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0] -\n",
            "[1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 0] (\n",
            "[1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 1 1 0 0 0] )\n",
            "[tensor([1., 0., 1., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 0., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
            "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 1., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
            "       device='cuda:0'), tensor([1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
            "       device='cuda:0'), tensor([1., 0., 1., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 0., 1., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
            "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
            "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0'), tensor([1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
            "        0., 0.], device='cuda:0'), tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
            "       device='cuda:0'), tensor([1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
            "       device='cuda:0'), tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
            "       device='cuda:0'), tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
            "        0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
            "        1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
            "        1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
            "        0., 0.], device='cuda:0'), tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
            "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.],\n",
            "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
            "        1., 0., 0., 0.], device='cuda:0')] tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
            "        36, 37, 38, 39, 40, 41, 42])\n"
          ]
        }
      ],
      "source": [
        "morse_code_numpy = {key:np.array([int(x) for x in MORSE_CODE_DICT[key].replace('.', '10').replace('-', '1110')] + [0, 0])\n",
        "                    for key in MORSE_CODE_DICT.keys()}\n",
        "\n",
        "for k in morse_code_numpy.keys():\n",
        "    print(morse_code_numpy[k], k)\n",
        "subset = list(morse_code_numpy.keys())\n",
        "\n",
        "id2key = subset\n",
        "key2id = {}\n",
        "for idx, s in enumerate(subset):\n",
        "    key2id[s] = idx\n",
        "\n",
        "X = [ttype(morse_code_numpy[k])for k in subset]\n",
        "Y = torch.LongTensor(np.arange(0,len(X)))\n",
        "print(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-03T01:08:07.166363Z",
          "start_time": "2021-05-03T01:08:07.161989Z"
        },
        "id": "7qHW4MiBHRXV"
      },
      "outputs": [],
      "source": [
        "class SITHCon_Classifier(nn.Module):\n",
        "    def __init__(self, out_classes, layer_params,\n",
        "                 act_func=nn.ReLU, batch_norm=False,\n",
        "                 dropout=.2):\n",
        "        super(SITHCon_Classifier, self).__init__()\n",
        "        last_channels = layer_params[-1]['channels']\n",
        "        self.transform_linears = nn.ModuleList([nn.Linear(l['channels'], l['channels'])\n",
        "                                                for l in layer_params])\n",
        "        self.sithcon_layers = nn.ModuleList([SITHCon_Layer(l, act_func) for l in layer_params])\n",
        "        self.to_out = nn.Linear(last_channels, out_classes)\n",
        "\n",
        "\n",
        "    def forward(self, inp):\n",
        "\n",
        "        x = inp\n",
        "        #out = []\n",
        "        for i in range(len(self.sithcon_layers)):\n",
        "            x = self.sithcon_layers[i](x)\n",
        "\n",
        "            x = self.transform_linears[i](x[:,0,:,:].transpose(1,2))\n",
        "            x = x.unsqueeze(1).transpose(2,3)\n",
        "\n",
        "            #out.append(x.clone())\n",
        "        x = x.transpose(2,3)[:, 0, :, :]\n",
        "        #x = x.transpose(2,3)[:, 0, :, :]\n",
        "        x = self.to_out(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBobaK1MHRXW"
      },
      "source": [
        "# Three Layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = [400, 35, 23, 2]\n",
        "\n",
        "sp1 = dict(in_features=1,\n",
        "           tau_min=.1, tau_max=4000, buff_max=6500,\n",
        "           dt=1, ntau=p[0], k=p[1], g=0.0, ttype=ttype,\n",
        "           channels=35, kernel_width=p[2], dilation=p[3],\n",
        "           dropout=None, batch_norm=None)\n",
        "sp2 = dict(in_features=sp1['channels'],\n",
        "           tau_min=.1, tau_max=4000, buff_max=6500,\n",
        "           dt=1, ntau=p[0], k=p[1], g=0.0, ttype=ttype,\n",
        "           channels=35, kernel_width=p[2], dilation=p[3],\n",
        "           dropout=None, batch_norm=None)\n",
        "sp3 = dict(in_features=sp2['channels'],\n",
        "           tau_min=.1, tau_max=4000, buff_max=6500,\n",
        "           dt=1, ntau=p[0], k=p[1], g=0.0, ttype=ttype,\n",
        "           channels=35, kernel_width=p[2], dilation=p[3],\n",
        "           dropout=None, batch_norm=None)\n",
        "\n",
        "# TWO LAYERS\n",
        "layer_params = [sp1, sp2]#, sp3]\n",
        "\n",
        "\n",
        "model = SITHCon_Classifier(len(X), layer_params, act_func=nn.ReLU).cuda()\n",
        "model\n",
        "tot_weights = 0\n",
        "for p in model.parameters():\n",
        "    tot_weights += p.numel()\n",
        "print(\"Total Weights:\", tot_weights)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwPZN53iNKWQ",
        "outputId": "a32719f2-f45f-45b7-e6c6-d5b09aa5ca95"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tau_min': 0.1, 'tau_max': 4000, 'buff_max': 6500, 'dt': 1, 'ntau': 400, 'k': 35, 'g': 0.0, 'ttype': <class 'torch.cuda.FloatTensor'>, 'dropout': None, 'batch_norm': None}\n",
            "{'tau_min': 0.1, 'tau_max': 4000, 'buff_max': 6500, 'dt': 1, 'ntau': 400, 'k': 35, 'g': 0.0, 'ttype': <class 'torch.cuda.FloatTensor'>, 'dropout': None, 'batch_norm': None}\n",
            "Total Weights: 33118\n",
            "SITHCon_Classifier(\n",
            "  (transform_linears): ModuleList(\n",
            "    (0-1): 2 x Linear(in_features=35, out_features=35, bias=True)\n",
            "  )\n",
            "  (sithcon_layers): ModuleList(\n",
            "    (0): SITHCon_Layer(\n",
            "      (tctct): _SITHCon_Core(\n",
            "        (sith): iSITH(ntau=400, tau_min=0.1, tau_max=4000, buff_max=6500, dt=1, k=35, g=0.0)\n",
            "        (conv): Conv2d(1, 35, kernel_size=(1, 23), stride=(1, 1), dilation=(1, 2), bias=False)\n",
            "        (maxp): MaxPool1d(kernel_size=356, stride=356, padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (act_func): ReLU()\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): SITHCon_Layer(\n",
            "      (tctct): _SITHCon_Core(\n",
            "        (sith): iSITH(ntau=400, tau_min=0.1, tau_max=4000, buff_max=6500, dt=1, k=35, g=0.0)\n",
            "        (conv): Conv2d(1, 35, kernel_size=(35, 23), stride=(1, 1), dilation=(1, 2), bias=False)\n",
            "        (maxp): MaxPool1d(kernel_size=356, stride=356, padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (act_func): ReLU()\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (to_out): Linear(in_features=35, out_features=43, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "epochs = 5000\n",
        "Trainscale = 10\n",
        "device='cuda'\n",
        "batch_size = 8\n",
        "batches = int(np.ceil(43 / batch_size))\n",
        "progress_bar = tqdm(range(int(epochs)), bar_format='{l_bar}{bar:5}{r_bar}{bar:-5b}')\n",
        "times_100 = 0\n",
        "for epoch_idx in progress_bar:\n",
        "    perfs = []\n",
        "    losses = []\n",
        "    model.train()\n",
        "    for batch_idx in range(batches):\n",
        "        optimizer.zero_grad()\n",
        "        loss = 0\n",
        "        permute = np.arange(0, 43)\n",
        "        for i in range(0, int(min(len(X) - (batch_idx*batch_size),\n",
        "                              batch_size))\n",
        "                       ):\n",
        "            iv = X[permute[batch_idx*batch_size + i]]\n",
        "            iv = iv.unsqueeze(0).unsqueeze(0).unsqueeze(0).to(device)\n",
        "            iv = iv.unsqueeze(-1)\n",
        "            iv = iv.repeat(1,1,1,1,Trainscale)\n",
        "            iv = iv.reshape(1,1,1,-1)\n",
        "            tv = Y[permute[batch_idx*batch_size + i]].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(iv)\n",
        "            loss += loss_func(out[:, -1, :],\n",
        "                             torch.cuda.LongTensor([tv]))\n",
        "            perfs.append((torch.argmax(out[:, -1, :], dim=-1) ==\n",
        "                      tv).sum().item())\n",
        "        loss = loss / min(len(X) - (batch_idx*batch_size),\n",
        "                          batch_size)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        #perfs = perfs[int(-loss_buffer_size/batch_size):]\n",
        "        losses.append(loss.detach().cpu().numpy())\n",
        "        #losses = losses[int(-loss_buffer_size/batch_size):]\n",
        "\n",
        "\n",
        "        s = \"{}:{:2} Loss: {:.4f}, Perf: {:.4f}\"\n",
        "        format_list = [epoch_idx, batch_idx, np.mean(losses),\n",
        "                       np.sum(perfs)/((len(perfs)))]\n",
        "        s = s.format(*format_list)\n",
        "        progress_bar.set_description(s)\n",
        "    if (np.sum(perfs)/((len(perfs))) == 1.0) & (np.mean(losses) < .11):\n",
        "        times_100 += 1\n",
        "        if times_100 >= 3:\n",
        "            break\n",
        "    else:\n",
        "        times_100 = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "067ca71308244f7dba4c14ae4bd27d5f",
            "461aaa3942fc446db65ec28b798bbf2c",
            "98e26a9e65634c848382a9a5f581d158",
            "05f3f96b430440b3a8e5955a0706c961",
            "bd1106aac3274341aab2e79db7f99e21",
            "2250680b64f94ec7b218e4ddd1a874d7",
            "28e4509d4f50492b812c320b0e1bc4c8",
            "4892f543bbda472c83cb02eff23b2cc7",
            "a7c0f051e6184430868040c13bfeb27c",
            "17265a79a922461a806f54b015dd15b2",
            "fbbbadf5d0934cef89c5c2d115a704f0"
          ]
        },
        "id": "ALaoXDaGNtqJ",
        "outputId": "364053c1-af6e-4184-f03f-69b8abae2c23"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|     | 0/5000 [00:00<?, ?it/s]     "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "067ca71308244f7dba4c14ae4bd27d5f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSCdia4zHRXa"
      },
      "source": [
        "# TEST\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-03T01:23:29.500713Z",
          "start_time": "2021-05-03T01:23:26.450075Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2_Bzo2UHRXa",
        "outputId": "bf2eac75-bfda-4c25-d045-4e9c08c58f95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0.11627906976744186\n",
            "2 0.3953488372093023\n",
            "5 0.9302325581395349\n",
            "6 1.0\n",
            "7 1.0\n",
            "8 1.0\n",
            "9 1.0\n",
            "10 1.0\n",
            "11 1.0\n",
            "12 1.0\n",
            "13 1.0\n",
            "14 1.0\n",
            "15 1.0\n",
            "16 1.0\n",
            "17 1.0\n",
            "18 1.0\n",
            "19 1.0\n",
            "20 1.0\n",
            "30 0.9767441860465116\n",
            "40 0.9534883720930233\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "evald = []\n",
        "evaldDict = {'perf':[],\n",
        "             'scale':[]}\n",
        "for nr in [1,2,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,30,40]:\n",
        "#for nr in range(1,40,):\n",
        "    perfs = []\n",
        "    for batch_idx, iv in enumerate(X):\n",
        "        iv = iv.unsqueeze(0).unsqueeze(0).unsqueeze(0).to(device)\n",
        "        iv = iv.unsqueeze(-1)\n",
        "        iv = iv.repeat(1,1,1,1,nr)\n",
        "        iv = iv.reshape(1,1,1,-1)\n",
        "        tv = Y[batch_idx].to(device)\n",
        "        out = model(iv)\n",
        "        loss = loss_func(out[:, -1, :],\n",
        "                         torch.cuda.LongTensor([tv]))\n",
        "\n",
        "\n",
        "        perfs.append((torch.argmax(out[:, -1, :], dim=-1) ==\n",
        "                      tv).sum().item())\n",
        "    evaldDict['perf'].append(sum(perfs)/len(perfs))\n",
        "    evaldDict['scale'].append(nr)\n",
        "    print(nr, sum(perfs)/len(perfs))\n",
        "    evald.append([nr, sum(perfs)/(len(perfs)*1.0)])\n",
        "scale_perfs = pd.DataFrame(evaldDict)\n",
        "directory = \"perf\"\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "scale_perfs.to_pickle(join(\"perf\", \"sithcon_morse_test.dill\"))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "067ca71308244f7dba4c14ae4bd27d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_461aaa3942fc446db65ec28b798bbf2c",
              "IPY_MODEL_98e26a9e65634c848382a9a5f581d158",
              "IPY_MODEL_05f3f96b430440b3a8e5955a0706c961"
            ],
            "layout": "IPY_MODEL_bd1106aac3274341aab2e79db7f99e21"
          }
        },
        "461aaa3942fc446db65ec28b798bbf2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2250680b64f94ec7b218e4ddd1a874d7",
            "placeholder": "​",
            "style": "IPY_MODEL_28e4509d4f50492b812c320b0e1bc4c8",
            "value": ""
          }
        },
        "98e26a9e65634c848382a9a5f581d158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4892f543bbda472c83cb02eff23b2cc7",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7c0f051e6184430868040c13bfeb27c",
            "value": 207
          }
        },
        "05f3f96b430440b3a8e5955a0706c961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17265a79a922461a806f54b015dd15b2",
            "placeholder": "​",
            "style": "IPY_MODEL_fbbbadf5d0934cef89c5c2d115a704f0",
            "value": "207: 5 Loss: 0.1068, Perf: 1.0000:   4%|▏    | 207/5000 [01:41&lt;38:24,  2.08it/s]     "
          }
        },
        "bd1106aac3274341aab2e79db7f99e21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2250680b64f94ec7b218e4ddd1a874d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28e4509d4f50492b812c320b0e1bc4c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4892f543bbda472c83cb02eff23b2cc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7c0f051e6184430868040c13bfeb27c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17265a79a922461a806f54b015dd15b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbbbadf5d0934cef89c5c2d115a704f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}