{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-05T14:52:20.948972Z",
          "start_time": "2021-05-05T14:52:20.939893Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyMApb_-nE3v",
        "outputId": "b75be443-070b-4e72-facf-8d38f01706d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 13 23:03:59 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8    14W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5pGZsxVnJqG",
        "outputId": "b1dd3b10-b209-41ae-c59d-11eae0ce4f3f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/VikashKumarShaw1994/DNN_invariant_time-rescaling.git DNN_invariant_sithcon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCccvTcHnQl5",
        "outputId": "eb6e9ed7-e548-43a3-9d0e-96e764781d32"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'DNN_invariant_sithcon' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-05T14:52:21.169340Z",
          "start_time": "2021-05-05T14:52:21.161864Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZkjuMARnE3w",
        "outputId": "88107361-6503-48aa-bc45-89af4f777b96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.cuda.FloatTensor'>\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "sn.set_context(\"poster\")\n",
        "\n",
        "import torch\n",
        "from torch import nn as nn\n",
        "ttype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
        "ctype = torch.cuda.LongTensor if torch.cuda.is_available() else torch.LongTensor\n",
        "print(ttype)\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import gridspec\n",
        "#from deepsith import DeepSITH\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import itertools\n",
        "from csv import DictWriter\n",
        "import os\n",
        "from os.path import join\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from math import factorial\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Braille_CODE_DICT = {\n",
        "\",\": \"01000000\",\n",
        "\".\": \"01001100\",\n",
        "\"(\": \"01001000\",\n",
        "\"-\": \"01100000\",\n",
        "\"/\": \"00100000\",\n",
        "\"?\": \"01100100\",\n",
        "\")\": \"01101000\",\n",
        "\"A\": \"10000010\",\n",
        "\"B\": \"11000010\",\n",
        "\"C\": \"10010010\",\n",
        "\"D\": \"10011010\",\n",
        "\"E\": \"10001010\",\n",
        "\"F\": \"11010010\",\n",
        "\"G\": \"11011010\",\n",
        "\"H\": \"11001010\",\n",
        "\"I\": \"01010010\",\n",
        "\"J\": \"01011010\",\n",
        "\"K\": \"10100010\",\n",
        "\"L\": \"11100010\",\n",
        "\"M\": \"10110010\",\n",
        "\"N\": \"10111010\",\n",
        "\"O\": \"10101010\",\n",
        "\"P\": \"11110010\",\n",
        "\"Q\": \"11111010\",\n",
        "\"R\": \"11101010\",\n",
        "\"S\": \"01110010\",\n",
        "\"T\": \"01111010\",\n",
        "\"U\": \"10100110\",\n",
        "\"V\": \"11100110\",\n",
        "\"W\": \"01011110\",\n",
        "\"X\": \"10110110\",\n",
        "\"Y\": \"10111110\",\n",
        "\"Z\": \"10101110\",\n",
        "\"1\": \"10000001\",\n",
        "\"2\": \"11000001\",\n",
        "\"3\": \"10010001\",\n",
        "\"4\": \"10011001\",\n",
        "\"5\": \"10001001\",\n",
        "\"6\": \"11010001\",\n",
        "\"7\": \"11011001\",\n",
        "\"8\": \"11001001\",\n",
        "\"9\": \"01010001\",\n",
        "\"0\": \"01011001\",\n",
        " }"
      ],
      "metadata": {
        "id": "ZXjblsh51APJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-04T18:44:55.050963Z",
          "start_time": "2021-05-04T18:44:55.025184Z"
        },
        "id": "9q9VOAHunE3y"
      },
      "outputs": [],
      "source": [
        "Braille_code_numpy = {key:np.array([int(x) for x in Braille_CODE_DICT[key]] + [0, 0])\n",
        "                    for key in Braille_CODE_DICT.keys()}\n",
        "subset = list(Braille_code_numpy.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-04T18:44:56.737830Z",
          "start_time": "2021-05-04T18:44:55.497500Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUbszhX9nE3z",
        "outputId": "1f9feef0-ffaa-410c-f213-493d1ac791d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(42)\n",
            "[tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), tensor([0., 1., 0., 0., 1., 1., 0., 0., 0., 0.], device='cuda:0'), tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0'), tensor([0., 1., 1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), tensor([0., 1., 1., 0., 0., 1., 0., 0., 0., 0.], device='cuda:0'), tensor([0., 1., 1., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 0., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 0., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 0., 1., 0., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 0., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 0., 0., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 0., 1., 0., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 0., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 0., 0., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([0., 1., 0., 1., 0., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([0., 1., 0., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 1., 0., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 0., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 1., 0., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([0., 1., 1., 1., 0., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([0., 1., 1., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 0., 0., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 0., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([0., 1., 0., 1., 1., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 1., 0., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 1., 1., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 0., 1., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0'), tensor([1., 1., 0., 0., 0., 0., 0., 1., 0., 0.], device='cuda:0'), tensor([1., 0., 0., 1., 0., 0., 0., 1., 0., 0.], device='cuda:0'), tensor([1., 0., 0., 1., 1., 0., 0., 1., 0., 0.], device='cuda:0'), tensor([1., 0., 0., 0., 1., 0., 0., 1., 0., 0.], device='cuda:0'), tensor([1., 1., 0., 1., 0., 0., 0., 1., 0., 0.], device='cuda:0'), tensor([1., 1., 0., 1., 1., 0., 0., 1., 0., 0.], device='cuda:0'), tensor([1., 1., 0., 0., 1., 0., 0., 1., 0., 0.], device='cuda:0'), tensor([0., 1., 0., 1., 0., 0., 0., 1., 0., 0.], device='cuda:0'), tensor([0., 1., 0., 1., 1., 0., 0., 1., 0., 0.], device='cuda:0')] tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
            "        36, 37, 38, 39, 40, 41, 42])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-b9b8c0fd878a>:6: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
            "  X = [ttype(Braille_code_numpy[k])for k in subset]\n"
          ]
        }
      ],
      "source": [
        "id2key = subset\n",
        "key2id = {}\n",
        "for idx, s in enumerate(subset):\n",
        "    key2id[s] = idx\n",
        "\n",
        "X = [ttype(Braille_code_numpy[k])for k in subset]\n",
        "Y = torch.LongTensor(np.arange(0,len(X)))\n",
        "print(Y.max())\n",
        "print(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-04T18:44:56.749737Z",
          "start_time": "2021-05-04T18:44:56.739072Z"
        },
        "id": "DmL3pGJ5nE3z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils import weight_norm\n",
        "\n",
        "\n",
        "class Chomp1d(nn.Module):\n",
        "    def __init__(self, chomp_size):\n",
        "        super(Chomp1d, self).__init__()\n",
        "        self.chomp_size = chomp_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x[:, :, :-self.chomp_size].contiguous()\n",
        "\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
        "        super(TemporalBlock, self).__init__()\n",
        "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
        "                                           stride=stride, padding=padding, dilation=dilation))\n",
        "        self.chomp1 = Chomp1d(padding)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
        "                                           stride=stride, padding=padding, dilation=dilation))\n",
        "        self.chomp2 = Chomp1d(padding)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
        "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
        "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
        "        self.relu = nn.ReLU()\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        self.conv1.weight.data.normal_(0, 0.01)\n",
        "        self.conv2.weight.data.normal_(0, 0.01)\n",
        "        if self.downsample is not None:\n",
        "            self.downsample.weight.data.normal_(0, 0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.relu(out + res)\n",
        "\n",
        "\n",
        "class TemporalConvNet(nn.Module):\n",
        "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
        "        super(TemporalConvNet, self).__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
        "            out_channels = num_channels[i]\n",
        "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
        "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "class TCN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):\n",
        "        super(TCN, self).__init__()\n",
        "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
        "        self.linear = nn.Linear(num_channels[-1], output_size)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        self.linear.weight.data.normal_(0, 0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y1 = self.tcn(x)\n",
        "        return self.linear(y1[:, :, -1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmwFG8t4nE30"
      },
      "source": [
        "# Three Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-04T18:44:57.765195Z",
          "start_time": "2021-05-04T18:44:57.754067Z"
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPdb_qvknE31",
        "outputId": "f4919944-7b59-42b8-83af-413f8f5cb193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Weights: 86868\n",
            "TCN(\n",
            "  (tcn): TemporalConvNet(\n",
            "    (network): Sequential(\n",
            "      (0): TemporalBlock(\n",
            "        (conv1): Conv1d(1, 25, kernel_size=(45,), stride=(1,), padding=(44,))\n",
            "        (chomp1): Chomp1d()\n",
            "        (relu1): ReLU()\n",
            "        (dropout1): Dropout(p=0.0, inplace=False)\n",
            "        (conv2): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(44,))\n",
            "        (chomp2): Chomp1d()\n",
            "        (relu2): ReLU()\n",
            "        (dropout2): Dropout(p=0.0, inplace=False)\n",
            "        (net): Sequential(\n",
            "          (0): Conv1d(1, 25, kernel_size=(45,), stride=(1,), padding=(44,))\n",
            "          (1): Chomp1d()\n",
            "          (2): ReLU()\n",
            "          (3): Dropout(p=0.0, inplace=False)\n",
            "          (4): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(44,))\n",
            "          (5): Chomp1d()\n",
            "          (6): ReLU()\n",
            "          (7): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (downsample): Conv1d(1, 25, kernel_size=(1,), stride=(1,))\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (1): TemporalBlock(\n",
            "        (conv1): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(88,), dilation=(2,))\n",
            "        (chomp1): Chomp1d()\n",
            "        (relu1): ReLU()\n",
            "        (dropout1): Dropout(p=0.0, inplace=False)\n",
            "        (conv2): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(88,), dilation=(2,))\n",
            "        (chomp2): Chomp1d()\n",
            "        (relu2): ReLU()\n",
            "        (dropout2): Dropout(p=0.0, inplace=False)\n",
            "        (net): Sequential(\n",
            "          (0): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(88,), dilation=(2,))\n",
            "          (1): Chomp1d()\n",
            "          (2): ReLU()\n",
            "          (3): Dropout(p=0.0, inplace=False)\n",
            "          (4): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(88,), dilation=(2,))\n",
            "          (5): Chomp1d()\n",
            "          (6): ReLU()\n",
            "          (7): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (linear): Linear(in_features=25, out_features=43, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
          ]
        }
      ],
      "source": [
        "model = TCN(1, 43, [25, 25], kernel_size=45, dropout=0.0).cuda()\n",
        "tot_weights = 0\n",
        "for p in model.parameters():\n",
        "    tot_weights += p.numel()\n",
        "print(\"Total Weights:\", tot_weights)\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-04T18:45:03.212417Z",
          "start_time": "2021-05-04T18:44:58.374076Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "7c8593a77a7a4dc6931a45a6972a3378",
            "89f38282bdb540e987693f6b2e789832",
            "9a8741b3a78a452f86e54a799ee9a817",
            "1d6dcd02436642a99dfae5239631eeb3",
            "4a1fe7073e6943b6a53a4b4f0a15087c",
            "ec9b0bb7f0fc4f13aee7620388cdd42a",
            "33749975f4574343a851547168af5a47",
            "5d6ebc5d908b432d965dbcf1ca4271ec",
            "61feb0c50f91401b8fd177ec8facd7bb",
            "186f5a63b60b418683b2a70cd9ea583c",
            "d5f7e32771054a2d9a216a25d6ba3574"
          ]
        },
        "id": "40cqWSynnE31",
        "outputId": "c39d6aeb-d863-4de2-f576-acbc250492aa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|     | 0/5000 [00:00<?, ?it/s]     "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c8593a77a7a4dc6931a45a6972a3378"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "epochs = 5000\n",
        "Trainscale = 10\n",
        "device='cuda'\n",
        "batch_size = 8\n",
        "batches = int(np.ceil(43 / batch_size))\n",
        "\n",
        "progress_bar = tqdm(range(int(epochs)), bar_format='{l_bar}{bar:5}{r_bar}{bar:-5b}')\n",
        "times_100 = 0\n",
        "\n",
        "for epoch_idx in progress_bar:\n",
        "    perfs = []\n",
        "    losses = []\n",
        "    model.train()\n",
        "    for batch_idx in range(batches):\n",
        "        optimizer.zero_grad()\n",
        "        loss = 0\n",
        "        permute = np.arange(0, 43)\n",
        "        for i in range(0, int(min(len(X) - (batch_idx*batch_size),\n",
        "                              batch_size))\n",
        "                       ):\n",
        "            iv = X[permute[batch_idx*batch_size + i]]\n",
        "            iv = iv.unsqueeze(0).unsqueeze(0).unsqueeze(-1)\n",
        "            iv = iv.repeat(1,1,1,Trainscale)\n",
        "            iv = iv.reshape(1,1,-1)\n",
        "            tv = Y[permute[batch_idx*batch_size + i]].to(device)\n",
        "            out = model(iv)\n",
        "            loss += loss_func(out,\n",
        "                         torch.cuda.LongTensor([tv]))\n",
        "            perfs.append((torch.argmax(out, dim=-1) ==\n",
        "                          tv).sum().item())\n",
        "\n",
        "\n",
        "        loss = loss / min(len(X) - (batch_idx*batch_size),\n",
        "                          batch_size)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        #perfs = perfs[int(-loss_buffer_size/batch_size):]\n",
        "        losses.append(loss.detach().cpu().numpy())\n",
        "        #losses = losses[int(-loss_buffer_size/batch_size):]\n",
        "\n",
        "\n",
        "        s = \"{}:{:2} Loss: {:.4f}, Perf: {:.4f}\"\n",
        "        format_list = [epoch_idx, batch_idx, np.mean(losses),\n",
        "                       np.sum(perfs)/((len(perfs)))]\n",
        "        s = s.format(*format_list)\n",
        "        progress_bar.set_description(s)\n",
        "    if (np.sum(perfs)/((len(perfs))) == 1.0) & (np.mean(losses) < .11):\n",
        "        times_100 += 1\n",
        "        if times_100 >= 3:\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-04T17:29:25.641192Z",
          "start_time": "2021-05-04T17:29:24.894817Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8SDwPu-nE31",
        "outputId": "2a7bea35-5811-4d19-f622-5b97ff9f24d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0.023255813953488372\n",
            "2 0.023255813953488372\n",
            "5 0.0\n",
            "6 0.023255813953488372\n",
            "7 0.0\n",
            "8 0.0\n",
            "9 0.0\n",
            "10 1.0\n",
            "11 0.06976744186046512\n",
            "12 0.0\n",
            "13 0.0\n",
            "14 0.023255813953488372\n",
            "15 0.023255813953488372\n",
            "16 0.023255813953488372\n",
            "17 0.023255813953488372\n",
            "18 0.023255813953488372\n",
            "19 0.023255813953488372\n",
            "20 0.023255813953488372\n",
            "30 0.023255813953488372\n",
            "40 0.023255813953488372\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "evald = []\n",
        "evaldDict = {'test_perf':[],\n",
        "             'rate':[]}\n",
        "for nr in [1,2,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,30,40]:\n",
        "#for nr in range(1,20):\n",
        "    perfs = []\n",
        "    for batch_idx, iv in enumerate(X):\n",
        "        iv = iv.unsqueeze(0).unsqueeze(0).unsqueeze(-1)\n",
        "        iv = iv.repeat(1,1,1,nr)\n",
        "        iv = iv.reshape(1,1,-1)\n",
        "        tv = Y[batch_idx].to(device)\n",
        "        out = model(iv)\n",
        "        loss = loss_func(out,\n",
        "                         torch.cuda.LongTensor([tv]))\n",
        "\n",
        "\n",
        "        perfs.append((torch.argmax(out, dim=-1) ==\n",
        "                      tv).sum().item())\n",
        "        #print(torch.argmax(out, dim=-1),\n",
        "        #              tv)\n",
        "    evaldDict['test_perf'].append(sum(perfs)/len(perfs))\n",
        "    evaldDict['rate'].append(nr)\n",
        "    print(nr, sum(perfs)/len(perfs))\n",
        "    evald.append({'scale':nr,\n",
        "                  'perf':sum(perfs)/len(perfs)})\n",
        "scale_perfs = pd.DataFrame(evald)\n",
        "scale_perfs.to_pickle(join(\"perf\", \"tcn_braille_test.dill\"))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7c8593a77a7a4dc6931a45a6972a3378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89f38282bdb540e987693f6b2e789832",
              "IPY_MODEL_9a8741b3a78a452f86e54a799ee9a817",
              "IPY_MODEL_1d6dcd02436642a99dfae5239631eeb3"
            ],
            "layout": "IPY_MODEL_4a1fe7073e6943b6a53a4b4f0a15087c"
          }
        },
        "89f38282bdb540e987693f6b2e789832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec9b0bb7f0fc4f13aee7620388cdd42a",
            "placeholder": "​",
            "style": "IPY_MODEL_33749975f4574343a851547168af5a47",
            "value": ""
          }
        },
        "9a8741b3a78a452f86e54a799ee9a817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d6ebc5d908b432d965dbcf1ca4271ec",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61feb0c50f91401b8fd177ec8facd7bb",
            "value": 26
          }
        },
        "1d6dcd02436642a99dfae5239631eeb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_186f5a63b60b418683b2a70cd9ea583c",
            "placeholder": "​",
            "style": "IPY_MODEL_d5f7e32771054a2d9a216a25d6ba3574",
            "value": "26: 5 Loss: 0.0607, Perf: 1.0000:   1%|     | 26/5000 [00:12&lt;12:28,  6.64it/s]     "
          }
        },
        "4a1fe7073e6943b6a53a4b4f0a15087c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec9b0bb7f0fc4f13aee7620388cdd42a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33749975f4574343a851547168af5a47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d6ebc5d908b432d965dbcf1ca4271ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61feb0c50f91401b8fd177ec8facd7bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "186f5a63b60b418683b2a70cd9ea583c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5f7e32771054a2d9a216a25d6ba3574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}