{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-12T14:25:11.423765Z",
          "start_time": "2021-05-12T14:25:11.253081Z"
        },
        "id": "2W-dSr6wEzTZ",
        "outputId": "b8de92cf-a2bf-48d6-de0b-19c8eafa62d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct 13 01:37:53 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/')"
      ],
      "metadata": {
        "id": "QZU4_4EiFBof",
        "outputId": "a3f6bfe4-8029-4109-f708-f18f332d2970",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/VikashKumarShaw1994/DNN_invariant_time-rescaling.git DNN_invariant_sithcon"
      ],
      "metadata": {
        "id": "Sf5fS3Kqr44e",
        "outputId": "3a6ef91e-93f3-45e8-ad06-b824e5fb50df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DNN_invariant_sithcon'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 60 (delta 19), reused 58 (delta 17), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (60/60), 6.88 MiB | 6.92 MiB/s, done.\n",
            "Resolving deltas: 100% (19/19), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-12T14:25:11.967687Z",
          "start_time": "2021-05-12T14:25:11.426139Z"
        },
        "id": "1OoDhsyjEzTa",
        "outputId": "2a27e815-f6f1-4c7c-b943-89fcc2b570b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.cuda.FloatTensor'>\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "sn.set_context(\"poster\")\n",
        "\n",
        "import torch\n",
        "from torch import nn as nn\n",
        "ttype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
        "ctype = torch.cuda.LongTensor if torch.cuda.is_available() else torch.LongTensor\n",
        "print(ttype)\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import gridspec\n",
        "from DNN_invariant_sithcon.SITHCon.sithcon import SITHCon_Layer\n",
        "#from SITHCon.SITHCon.sithcon import SITHCon_Layer, _SITHCon_Core, iSITH\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import itertools\n",
        "from csv import DictWriter\n",
        "import os\n",
        "from os.path import join\n",
        "import glob\n",
        "ttype=torch.cuda.FloatTensor\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from math import factorial\n",
        "import random\n",
        "from itertools import combinations_with_replacement as comb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-12T14:25:11.971556Z",
          "start_time": "2021-05-12T14:25:11.968917Z"
        },
        "id": "RYgc_pPXEzTb"
      },
      "outputs": [],
      "source": [
        "MORSE_CODE_DICT = {'1':'.----', '2':'..---', '3':'...--',\n",
        "                    '4':'....-', '5':'.....', '6':'-....',\n",
        "                    '7':'--...', '8':'---..', '9':'----.',\n",
        "                    '0':'-----', }\n",
        "\n",
        "# SHORTER\n",
        "MORSE_CODE_DICT = {'1':'.-', '2':'-...',\n",
        "                    '3':'-.-.', '4':'-..', '5':'.',\n",
        "                    '6':'..-.', '7':'--.', '8':'....',\n",
        "                    '9':'..', '0':'.---',}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-12T14:25:11.985734Z",
          "start_time": "2021-05-12T14:25:11.972669Z"
        },
        "id": "adIdlNH9EzTc",
        "outputId": "68fbc273-4cde-49ce-92e4-5571a59d6d5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[1 0 1 1 1 0 0 0] 1\n",
            "[1 1 1 0 1 0 1 0 1 0 0 0] 2\n",
            "[1 1 1 0 1 0 1 1 1 0 1 0 0 0] 3\n",
            "[1 1 1 0 1 0 1 0 0 0] 4\n",
            "[1 0 0 0] 5\n",
            "[1 0 1 0 1 1 1 0 1 0 0 0] 6\n",
            "[1 1 1 0 1 1 1 0 1 0 0 0] 7\n",
            "[1 0 1 0 1 0 1 0 0 0] 8\n",
            "[1 0 1 0 0 0] 9\n",
            "[1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 0] 0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print()\n",
        "morse_code_numpy = {key:np.array([int(x) for x in MORSE_CODE_DICT[key].replace('.', '10').replace('-', '1110')] + [0, 0])\n",
        "                    for key in MORSE_CODE_DICT.keys()}\n",
        "for k in morse_code_numpy.keys():\n",
        "    print(morse_code_numpy[k], k)\n",
        "subset = list(morse_code_numpy.keys())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-12T14:25:12.113548Z",
          "start_time": "2021-05-12T14:25:11.986453Z"
        },
        "id": "EaDSIDUlEzTc",
        "outputId": "898c5b34-2e0d-44ad-bbab-b5a2c48a43cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-27460976e734>:13: DeprecationWarning: Sampling from a set deprecated\n",
            "since Python 3.9 and will be removed in a subsequent version.\n",
            "  k = random.sample(keys, 1)[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(260, 2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def gen_item(samples=10, scale=5, target_scale=.1):\n",
        "    # We can tests 1s the same length as the items added together or 1 at the end only.\n",
        "    keys = morse_code_numpy.keys()\n",
        "    dim1 = []\n",
        "    dim2 = []\n",
        "    half = int(samples / 2)\n",
        "    added_indexes = [np.random.randint(half),\n",
        "                     np.random.randint(half, samples)]\n",
        "\n",
        "    answer = 0\n",
        "    for s in range(samples):\n",
        "        # Grab Random Morse Code Letter\n",
        "        k = random.sample(keys, 1)[0]\n",
        "        mcl = morse_code_numpy[k]\n",
        "        Mmcl = mcl.repeat(scale)\n",
        "        dim1.append(Mmcl[:, np.newaxis])\n",
        "        if s in added_indexes:\n",
        "\n",
        "            # dim2.append(np.ones(Mmcl.shape[0])[:, np.newaxis])\n",
        "            temp = np.zeros(Mmcl.shape[0])[:, np.newaxis]\n",
        "            temp[-scale:] = 1.0\n",
        "            #temp[-1] = 1.0 # TRY THIS AT SOME POINT\n",
        "            dim2.append(temp)\n",
        "            answer += int(k)\n",
        "        else:\n",
        "            dim2.append(np.zeros(Mmcl.shape[0])[:, np.newaxis])\n",
        "    inp = np.concatenate([np.concatenate(dim1, axis=0),\n",
        "                          np.concatenate(dim2, axis=0)], axis=1)\n",
        "\n",
        "    target = np.array([answer])\n",
        "    return inp, target*target_scale\n",
        "inp, tar = gen_item(5, 5, .1)\n",
        "print(inp.shape)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.imshow(inp.T,aspect='auto', interpolation='none')\n",
        "plt.title(\"Answer: {:.2f}\".format(tar[0]))\n",
        "plt.yticks([])\n",
        "plt.savefig(join('figs', 'adding_morse_example'), dpi=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-12T14:25:12.257458Z",
          "start_time": "2021-05-12T14:25:12.214501Z"
        },
        "id": "gTzquDfYEzTc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils import weight_norm\n",
        "\n",
        "\n",
        "class Chomp1d(nn.Module):\n",
        "    def __init__(self, chomp_size):\n",
        "        super(Chomp1d, self).__init__()\n",
        "        self.chomp_size = chomp_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x[:, :, :-self.chomp_size].contiguous()\n",
        "\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
        "        super(TemporalBlock, self).__init__()\n",
        "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
        "                                           stride=stride, padding=padding, dilation=dilation))\n",
        "        self.chomp1 = Chomp1d(padding)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
        "                                           stride=stride, padding=padding, dilation=dilation))\n",
        "        self.chomp2 = Chomp1d(padding)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
        "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
        "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
        "        self.relu = nn.ReLU()\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        self.conv1.weight.data.normal_(0, 0.01)\n",
        "        self.conv2.weight.data.normal_(0, 0.01)\n",
        "        if self.downsample is not None:\n",
        "            self.downsample.weight.data.normal_(0, 0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.relu(out + res)\n",
        "\n",
        "\n",
        "class TemporalConvNet(nn.Module):\n",
        "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
        "        super(TemporalConvNet, self).__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
        "            out_channels = num_channels[i]\n",
        "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
        "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "class TCN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):\n",
        "        super(TCN, self).__init__()\n",
        "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
        "        self.linear = nn.Linear(num_channels[-1], output_size)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        self.linear.weight.data.normal_(0, 0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y1 = self.tcn(x)\n",
        "        return self.linear(y1[:, :, -1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEARXU6nEzTd"
      },
      "source": [
        "# Three Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-12T14:25:12.982073Z",
          "start_time": "2021-05-12T14:25:12.972372Z"
        },
        "id": "0P9ENseHEzTe"
      },
      "outputs": [],
      "source": [
        "def gen_model(p):\n",
        "    model = TCN(2, 1, [25, 25, 25, 25,25,25,25,25], kernel_size=45, dropout=0.0).cuda()\n",
        "    return model\n",
        "\n",
        "def test_model(model, X, Y):\n",
        "    model.eval()\n",
        "    evald = []\n",
        "    evaldDict = {'test_perf':[],\n",
        "                 'rate':[],\n",
        "                 'tau_max':[],\n",
        "                 'ntau':[],\n",
        "                 'k':[]}\n",
        "\n",
        "    # BIG NOTE\n",
        "    # BIG NOTE\n",
        "    # BIG NOTE\n",
        "    # Generate the test items once, use in all models at all scales.\n",
        "    model.eval()\n",
        "    evald = []\n",
        "    evaldDict = {'test_perf':[],\n",
        "                 'rate':[]}\n",
        "    for nr in range(1,20):\n",
        "        losses = []\n",
        "        for iv, tar in items:\n",
        "\n",
        "            iv = ttype(iv).unsqueeze(0).unsqueeze(0).transpose(-1,-2).unsqueeze(-1)\n",
        "            iv = iv.repeat(1,1,1,1,nr)\n",
        "            iv = iv.reshape(1,1,2,-1)\n",
        "            tv = torch.FloatTensor(tar).to(device)\n",
        "            out = model(iv)\n",
        "\n",
        "            loss = loss_func(out[:, -1, :],\n",
        "                                 tv)\n",
        "            losses.append(loss.detach().cpu().numpy())\n",
        "        print(nr, np.mean(losses))\n",
        "        evaldDict['test_perf'].append(np.mean(losses))\n",
        "        evaldDict['rate'].append(nr)\n",
        "        evaldDict['tau_max'].append(model.sithcon_layers[0].sithcon.sith.tau_max)\n",
        "        evaldDict['ntau'].append(model.sithcon_layers[0].sithcon.sith.ntau)\n",
        "        evaldDict['k'].append(model.sithcon_layers[0].sithcon.sith.k)\n",
        "    return evaldDict\n",
        "\n",
        "def save_outcome(outcome, filename):\n",
        "    dat = pd.DataFrame(outcome)\n",
        "    dat.to_csv(join('perf',filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-12T14:25:14.935158Z",
          "start_time": "2021-05-12T14:25:14.929667Z"
        },
        "id": "_7W0svbTEzTe"
      },
      "outputs": [],
      "source": [
        "params = [\n",
        "           [None],]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-12T14:25:16.436250Z",
          "start_time": "2021-05-12T14:25:15.509742Z"
        },
        "id": "W13ijOhLEzTe",
        "outputId": "9d45957f-bda6-47c2-8aab-b62cbfe91d73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Weights: 425026\n",
            "TCN(\n",
            "  (tcn): TemporalConvNet(\n",
            "    (network): Sequential(\n",
            "      (0): TemporalBlock(\n",
            "        (conv1): Conv1d(2, 25, kernel_size=(45,), stride=(1,), padding=(44,))\n",
            "        (chomp1): Chomp1d()\n",
            "        (relu1): ReLU()\n",
            "        (dropout1): Dropout(p=0.0, inplace=False)\n",
            "        (conv2): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(44,))\n",
            "        (chomp2): Chomp1d()\n",
            "        (relu2): ReLU()\n",
            "        (dropout2): Dropout(p=0.0, inplace=False)\n",
            "        (net): Sequential(\n",
            "          (0): Conv1d(2, 25, kernel_size=(45,), stride=(1,), padding=(44,))\n",
            "          (1): Chomp1d()\n",
            "          (2): ReLU()\n",
            "          (3): Dropout(p=0.0, inplace=False)\n",
            "          (4): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(44,))\n",
            "          (5): Chomp1d()\n",
            "          (6): ReLU()\n",
            "          (7): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (downsample): Conv1d(2, 25, kernel_size=(1,), stride=(1,))\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (1): TemporalBlock(\n",
            "        (conv1): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(88,), dilation=(2,))\n",
            "        (chomp1): Chomp1d()\n",
            "        (relu1): ReLU()\n",
            "        (dropout1): Dropout(p=0.0, inplace=False)\n",
            "        (conv2): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(88,), dilation=(2,))\n",
            "        (chomp2): Chomp1d()\n",
            "        (relu2): ReLU()\n",
            "        (dropout2): Dropout(p=0.0, inplace=False)\n",
            "        (net): Sequential(\n",
            "          (0): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(88,), dilation=(2,))\n",
            "          (1): Chomp1d()\n",
            "          (2): ReLU()\n",
            "          (3): Dropout(p=0.0, inplace=False)\n",
            "          (4): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(88,), dilation=(2,))\n",
            "          (5): Chomp1d()\n",
            "          (6): ReLU()\n",
            "          (7): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (2): TemporalBlock(\n",
            "        (conv1): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(176,), dilation=(4,))\n",
            "        (chomp1): Chomp1d()\n",
            "        (relu1): ReLU()\n",
            "        (dropout1): Dropout(p=0.0, inplace=False)\n",
            "        (conv2): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(176,), dilation=(4,))\n",
            "        (chomp2): Chomp1d()\n",
            "        (relu2): ReLU()\n",
            "        (dropout2): Dropout(p=0.0, inplace=False)\n",
            "        (net): Sequential(\n",
            "          (0): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(176,), dilation=(4,))\n",
            "          (1): Chomp1d()\n",
            "          (2): ReLU()\n",
            "          (3): Dropout(p=0.0, inplace=False)\n",
            "          (4): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(176,), dilation=(4,))\n",
            "          (5): Chomp1d()\n",
            "          (6): ReLU()\n",
            "          (7): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (3): TemporalBlock(\n",
            "        (conv1): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(352,), dilation=(8,))\n",
            "        (chomp1): Chomp1d()\n",
            "        (relu1): ReLU()\n",
            "        (dropout1): Dropout(p=0.0, inplace=False)\n",
            "        (conv2): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(352,), dilation=(8,))\n",
            "        (chomp2): Chomp1d()\n",
            "        (relu2): ReLU()\n",
            "        (dropout2): Dropout(p=0.0, inplace=False)\n",
            "        (net): Sequential(\n",
            "          (0): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(352,), dilation=(8,))\n",
            "          (1): Chomp1d()\n",
            "          (2): ReLU()\n",
            "          (3): Dropout(p=0.0, inplace=False)\n",
            "          (4): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(352,), dilation=(8,))\n",
            "          (5): Chomp1d()\n",
            "          (6): ReLU()\n",
            "          (7): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (4): TemporalBlock(\n",
            "        (conv1): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(704,), dilation=(16,))\n",
            "        (chomp1): Chomp1d()\n",
            "        (relu1): ReLU()\n",
            "        (dropout1): Dropout(p=0.0, inplace=False)\n",
            "        (conv2): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(704,), dilation=(16,))\n",
            "        (chomp2): Chomp1d()\n",
            "        (relu2): ReLU()\n",
            "        (dropout2): Dropout(p=0.0, inplace=False)\n",
            "        (net): Sequential(\n",
            "          (0): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(704,), dilation=(16,))\n",
            "          (1): Chomp1d()\n",
            "          (2): ReLU()\n",
            "          (3): Dropout(p=0.0, inplace=False)\n",
            "          (4): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(704,), dilation=(16,))\n",
            "          (5): Chomp1d()\n",
            "          (6): ReLU()\n",
            "          (7): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (5): TemporalBlock(\n",
            "        (conv1): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(1408,), dilation=(32,))\n",
            "        (chomp1): Chomp1d()\n",
            "        (relu1): ReLU()\n",
            "        (dropout1): Dropout(p=0.0, inplace=False)\n",
            "        (conv2): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(1408,), dilation=(32,))\n",
            "        (chomp2): Chomp1d()\n",
            "        (relu2): ReLU()\n",
            "        (dropout2): Dropout(p=0.0, inplace=False)\n",
            "        (net): Sequential(\n",
            "          (0): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(1408,), dilation=(32,))\n",
            "          (1): Chomp1d()\n",
            "          (2): ReLU()\n",
            "          (3): Dropout(p=0.0, inplace=False)\n",
            "          (4): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(1408,), dilation=(32,))\n",
            "          (5): Chomp1d()\n",
            "          (6): ReLU()\n",
            "          (7): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (6): TemporalBlock(\n",
            "        (conv1): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(2816,), dilation=(64,))\n",
            "        (chomp1): Chomp1d()\n",
            "        (relu1): ReLU()\n",
            "        (dropout1): Dropout(p=0.0, inplace=False)\n",
            "        (conv2): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(2816,), dilation=(64,))\n",
            "        (chomp2): Chomp1d()\n",
            "        (relu2): ReLU()\n",
            "        (dropout2): Dropout(p=0.0, inplace=False)\n",
            "        (net): Sequential(\n",
            "          (0): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(2816,), dilation=(64,))\n",
            "          (1): Chomp1d()\n",
            "          (2): ReLU()\n",
            "          (3): Dropout(p=0.0, inplace=False)\n",
            "          (4): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(2816,), dilation=(64,))\n",
            "          (5): Chomp1d()\n",
            "          (6): ReLU()\n",
            "          (7): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (7): TemporalBlock(\n",
            "        (conv1): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(5632,), dilation=(128,))\n",
            "        (chomp1): Chomp1d()\n",
            "        (relu1): ReLU()\n",
            "        (dropout1): Dropout(p=0.0, inplace=False)\n",
            "        (conv2): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(5632,), dilation=(128,))\n",
            "        (chomp2): Chomp1d()\n",
            "        (relu2): ReLU()\n",
            "        (dropout2): Dropout(p=0.0, inplace=False)\n",
            "        (net): Sequential(\n",
            "          (0): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(5632,), dilation=(128,))\n",
            "          (1): Chomp1d()\n",
            "          (2): ReLU()\n",
            "          (3): Dropout(p=0.0, inplace=False)\n",
            "          (4): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(5632,), dilation=(128,))\n",
            "          (5): Chomp1d()\n",
            "          (6): ReLU()\n",
            "          (7): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (linear): Linear(in_features=25, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = gen_model(params[0])\n",
        "\n",
        "\n",
        "tot_weights = 0\n",
        "for p in model.parameters():\n",
        "    tot_weights += p.numel()\n",
        "print(\"Total Weights:\", tot_weights)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-12T15:50:55.896402Z",
          "start_time": "2021-05-12T14:25:31.166680Z"
        },
        "id": "0IP12J8NEzTf",
        "outputId": "1c33643a-9153-4a98-cb78-03c341c17679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529,
          "referenced_widgets": [
            "0d4d2d904b6e4f8caab7a0d56f06071f",
            "f700b64be9e14e24a3a0ca559145aec2",
            "68e340335efd4395a07cac262497b490",
            "fdf9ad8f960e488fa4d34556ff40ee32",
            "23ef95c9ec674ca1bc06f8aa1a5c2768",
            "845a345afe5e4b4fb7e497ec8a8b7457",
            "07b46ca28833438d9b2a6270fa19d34a",
            "c7e81d61bb294e07ae58399d2409f8b5",
            "96a05ec201d9445481befc8ca89fde2c",
            "031671abd4954785b9e7605ae7605a09",
            "1de257887ae94c00a47bed82058c04af"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|     | 0/500 [00:00<?, ?it/s]     "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d4d2d904b6e4f8caab7a0d56f06071f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-27460976e734>:13: DeprecationWarning: Sampling from a set deprecated\n",
            "since Python 3.9 and will be removed in a subsequent version.\n",
            "  k = random.sample(keys, 1)[0]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-01a2cc6c515d>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0miv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mttype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mtv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mttype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             loss += loss_func(out,\n\u001b[1;32m     24\u001b[0m                               tv)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-66e8190c730e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-66e8190c730e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTCN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-66e8190c730e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-66e8190c730e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchomp_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "loss_func = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "Trainscale = 5\n",
        "epochs = 500\n",
        "trials_per_epoch = 1000\n",
        "batch_size = 32\n",
        "device='cuda'\n",
        "progress_bar = tqdm(range(int(epochs)), bar_format='{l_bar}{bar:5}{r_bar}{bar:-5b}')\n",
        "\n",
        "for epoch_idx in progress_bar:\n",
        "    perfs = []\n",
        "    losses = []\n",
        "    model.train()\n",
        "    for batch_idx in range(trials_per_epoch):\n",
        "        optimizer.zero_grad()\n",
        "        loss = 0\n",
        "        for i in range(batch_size):\n",
        "            iv, tar = gen_item(10, Trainscale, .1)\n",
        "            iv = ttype(iv).unsqueeze(0).transpose(-1,-2)\n",
        "            tv = ttype(tar)\n",
        "            out = model(iv)\n",
        "            loss += loss_func(out,\n",
        "                              tv)\n",
        "        loss = loss / batch_size\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        perfs.append(0)\n",
        "        #perfs = perfs[int(-loss_buffer_size/batch_size):]\n",
        "        losses.append(loss.detach().cpu().numpy())\n",
        "        #losses = losses[int(-loss_buffer_size/batch_size):]\n",
        "\n",
        "\n",
        "        s = \"{}:{:2} Loss: {:.4f}, Perf: {:.4f}\"\n",
        "        format_list = [epoch_idx, batch_idx, np.mean(losses),\n",
        "                       np.sum(perfs)/((len(perfs)))]\n",
        "        s = s.format(*format_list)\n",
        "        progress_bar.set_description(s)\n",
        "    if (np.sum(perfs)/((len(perfs))) == 1.0) & (np.mean(losses) < .11):\n",
        "      times_100 += 1\n",
        "      if times_100 >= 3:\n",
        "        break\n",
        "      else:\n",
        "        times_100 = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gPkP7MYDJ1uF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-12T15:51:06.449121Z",
          "start_time": "2021-05-12T15:51:06.439344Z"
        },
        "id": "aOKP7gSQEzTf"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'TCN_MorseAdding_5122021.pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "items = []\n",
        "for i in range(1000):\n",
        "    iv, tar = gen_item(10, 1, .1)\n",
        "    items.append([iv, tar])\n",
        "np.save('generated_adding_morse',items)"
      ],
      "metadata": {
        "id": "693BXeYMtYgx",
        "outputId": "fa69be7f-f5dc-45e3-8526-ca2e0da7e403",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-27460976e734>:13: DeprecationWarning: Sampling from a set deprecated\n",
            "since Python 3.9 and will be removed in a subsequent version.\n",
            "  k = random.sample(keys, 1)[0]\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:521: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-12T15:51:09.062210Z",
          "start_time": "2021-05-12T15:51:09.054008Z"
        },
        "id": "PQ7FQMvBEzTf"
      },
      "outputs": [],
      "source": [
        "items = np.load('generated_adding_morse.npy', allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-12T15:52:03.713792Z",
          "start_time": "2021-05-12T15:51:15.691742Z"
        },
        "id": "9zckBkFIEzTf",
        "outputId": "509e9d87-f984-48db-ff9a-c38fe9a74a50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0.78586096\n",
            "2 0.41909364\n",
            "3 0.22513774\n",
            "4 0.17928582\n",
            "5 0.1623966\n",
            "6 0.17146687\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# The data below printed is not the actual data, Needs to run on CUDA again, Using previous dill files\n",
        "# BIG NOTE\n",
        "# BIG NOTE\n",
        "# Generate the test items once, use in all models at all scales.\n",
        "model.eval()\n",
        "evald = []\n",
        "device=\"cuda\"\n",
        "evaldDict = {'test_perf':[],\n",
        "             'rate':[]}\n",
        "for nr in range(1,20):\n",
        "    losses = []\n",
        "    for iv, tar in items:\n",
        "\n",
        "\n",
        "        iv = ttype(iv).unsqueeze(0).transpose(-1,-2).unsqueeze(-1)\n",
        "        iv = iv.repeat(1,1,1,nr)\n",
        "        iv = iv.reshape(1,2,-1)\n",
        "        tv = torch.FloatTensor(tar).to(device)\n",
        "        out = model(iv)\n",
        "        loss = loss_func(out,\n",
        "                             tv)\n",
        "        losses.append(loss.detach().cpu().numpy())\n",
        "    print(nr, np.mean(losses))\n",
        "    evaldDict['test_perf'].append(np.mean(losses))\n",
        "    evaldDict['rate'].append(nr)\n",
        "    evald.append([nr, np.mean(losses)])\n",
        "scale_perfs = pd.DataFrame(evaldDict)\n",
        "directory = \"perf\"\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "scale_perfs.to_pickle(join(\"perf\", \"tcn_morseadding_test.dill\"))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": false,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "47.7167px",
        "left": "1045.97px",
        "top": "52px",
        "width": "161.033px"
      },
      "toc_section_display": false,
      "toc_window_display": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d4d2d904b6e4f8caab7a0d56f06071f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f700b64be9e14e24a3a0ca559145aec2",
              "IPY_MODEL_68e340335efd4395a07cac262497b490",
              "IPY_MODEL_fdf9ad8f960e488fa4d34556ff40ee32"
            ],
            "layout": "IPY_MODEL_23ef95c9ec674ca1bc06f8aa1a5c2768"
          }
        },
        "f700b64be9e14e24a3a0ca559145aec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_845a345afe5e4b4fb7e497ec8a8b7457",
            "placeholder": "​",
            "style": "IPY_MODEL_07b46ca28833438d9b2a6270fa19d34a",
            "value": ""
          }
        },
        "68e340335efd4395a07cac262497b490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7e81d61bb294e07ae58399d2409f8b5",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96a05ec201d9445481befc8ca89fde2c",
            "value": 0
          }
        },
        "fdf9ad8f960e488fa4d34556ff40ee32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_031671abd4954785b9e7605ae7605a09",
            "placeholder": "​",
            "style": "IPY_MODEL_1de257887ae94c00a47bed82058c04af",
            "value": "0:67 Loss: 0.2717, Perf: 0.0000:   0%|     | 0/500 [00:22&lt;?, ?it/s]     "
          }
        },
        "23ef95c9ec674ca1bc06f8aa1a5c2768": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "845a345afe5e4b4fb7e497ec8a8b7457": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07b46ca28833438d9b2a6270fa19d34a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7e81d61bb294e07ae58399d2409f8b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96a05ec201d9445481befc8ca89fde2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "031671abd4954785b9e7605ae7605a09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1de257887ae94c00a47bed82058c04af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}