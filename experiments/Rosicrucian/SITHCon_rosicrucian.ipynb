{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf3KhYlVIfNz",
        "outputId": "1fcb576d-ce62-45bc-dda9-b72468175cae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 30 00:12:43 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/')"
      ],
      "metadata": {
        "id": "Q1oW5m7LLjHz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d2fec50-ae68-43bb-8d2d-05c2eeb08f6c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-03T01:36:37.390727Z",
          "start_time": "2021-05-03T01:36:37.208757Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BojtTyJHRXN",
        "outputId": "40e15e80-f078-4893-b831-d68210c40723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'DNN_invariant_sithcon' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "!git clone https://github.com/VikashKumarShaw1994/DNN_invariant_time-rescaling.git DNN_invariant_sithcon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-03T01:36:37.943324Z",
          "start_time": "2021-05-03T01:36:37.391688Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ-T_7LVHRXR",
        "outputId": "b12fbb68-bd14-4993-d576-7a99b224f253"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.cuda.FloatTensor'>\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "sn.set_context(\"poster\")\n",
        "\n",
        "import torch\n",
        "from torch import nn as nn\n",
        "ttype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
        "ctype = torch.cuda.LongTensor if torch.cuda.is_available() else torch.LongTensor\n",
        "print(ttype)\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import gridspec\n",
        "from DNN_invariant_sithcon.SITHCon.sithcon import SITHCon_Layer\n",
        "#from sithcon import SITHCon_Layer, _SITHCon_Core, iSITH\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import itertools\n",
        "from csv import DictWriter\n",
        "import os\n",
        "from os.path import join\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from math import factorial\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rosicrucian_cipher = {\n",
        "    'A': '☉',\n",
        "    'B': '☿',\n",
        "    'C': '♀',\n",
        "    'D': '☽☿',\n",
        "    'E': '☉♀',\n",
        "    'F': '☽☽',\n",
        "    'G': '☽♀',\n",
        "    'H': '☽☉',\n",
        "    'I': '☉☉',\n",
        "    'J': '☿♀',\n",
        "    'K': '☽☉☽',\n",
        "    'L': '☽☽♀',\n",
        "    'M': '☽☿☽',\n",
        "    'N': '☽',\n",
        "    'O': '☉☉',\n",
        "    'P': '☉☽',\n",
        "    'Q': '☽☉',\n",
        "    'R': '☉☉☽',\n",
        "    'S': '☉☉☉',\n",
        "    'T': '☽☽☽',\n",
        "    'U': '☉☉♀',\n",
        "    'V': '☉☉☽☽',\n",
        "    'W': '☽☽☽☽',\n",
        "    'X': '☽☉☉☉',\n",
        "    'Y': '☽☉☽☉',\n",
        "    'Z': '☽☉☉☉☉',\n",
        "    '0': '♀☽☽☽☽',\n",
        "    '1': '☉☽☽☽☽',\n",
        "    '2': '☉☉☽☽☽',\n",
        "    '3': '☉☉☉☽☽',\n",
        "    '4': '☉☉☉☉☽',\n",
        "    '5': '☉☉☉☉☉',\n",
        "    '6': '♀☉☉☉☉',\n",
        "    '7': '☽♀☉☉☉',\n",
        "    '8': '☽☽♀☉☉',\n",
        "    '9': '☽☽☽♀☉',\n",
        "    ',': '♀☽',\n",
        "    '.': '☉☽☉☽',\n",
        "    '(': '☽☉☉☉☽',\n",
        "    ')': '☽☉☉☉☉',\n",
        "    '/': '☉☽☽☉',\n",
        "    '?': '☽☽♀☽☉',\n",
        "    '-': '☽☉☉☽☉',\n",
        "}\n",
        "\n",
        "\n",
        "message = \"CRYPTO\"\n",
        "binary_representation = ''.join([rosicrucian_cipher[char] for char in message])\n",
        "\n",
        "print(binary_representation)\n"
      ],
      "metadata": {
        "id": "8pEB7bab1k38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ab47653-090b-4447-b8aa-b8270b9233a5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "♀☉☉☽☽☉☽☉☉☽☽☽☽☉☉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rosicrucian_to_binary = {\n",
        "    '☉': '00',\n",
        "    '☿': '01',\n",
        "    '♀': '10',\n",
        "    '☽': '11',\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "print(binary_representation)\n",
        "\n",
        "def rosicruciantobinary(rosicrucian_message):\n",
        "    binary_representation = ''.join([rosicrucian_to_binary[char] for char in rosicrucian_message])\n",
        "\n",
        "    return binary_representation\n",
        "\n",
        "rosicrucian_cipher_dict={}\n",
        "for brk,brv in rosicrucian_cipher.items():\n",
        "    rosicrucian_cipher_dict[brk]=rosicruciantobinary(brv)\n",
        "print(rosicrucian_cipher_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNbRDHgKSndR",
        "outputId": "472852ff-71a0-4092-a488-ec95abb8cc3f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000011111100110000000000\n",
            "{'A': '00', 'B': '01', 'C': '10', 'D': '1101', 'E': '0010', 'F': '1111', 'G': '1110', 'H': '1100', 'I': '0000', 'J': '0110', 'K': '110011', 'L': '111110', 'M': '110111', 'N': '11', 'O': '0000', 'P': '0011', 'Q': '1100', 'R': '000011', 'S': '000000', 'T': '111111', 'U': '000010', 'V': '00001111', 'W': '11111111', 'X': '11000000', 'Y': '11001100', 'Z': '1100000000', '0': '1011111111', '1': '0011111111', '2': '0000111111', '3': '0000001111', '4': '0000000011', '5': '0000000000', '6': '1000000000', '7': '1110000000', '8': '1111100000', '9': '1111111000', ',': '1011', '.': '00110011', '(': '1100000011', ')': '1100000000', '/': '00111100', '?': '1111101100', '-': '1100001100'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-03T01:08:04.845819Z",
          "start_time": "2021-05-03T01:08:04.831952Z"
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knjD1UwEHRXU",
        "outputId": "214a74ff-dc34-41f1-d01a-e10632ff8c07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([0., 0., 0., 0.], device='cuda:0'), tensor([0., 1., 0., 0.], device='cuda:0'), tensor([1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 0., 1., 0., 0.], device='cuda:0'), tensor([0., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 1., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 0., 0., 0., 0.], device='cuda:0'), tensor([0., 0., 0., 0., 0., 0.], device='cuda:0'), tensor([0., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 0., 0., 1., 1., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 0., 1., 1., 1., 0., 0.], device='cuda:0'), tensor([1., 1., 0., 0.], device='cuda:0'), tensor([0., 0., 0., 0., 0., 0.], device='cuda:0'), tensor([0., 0., 1., 1., 0., 0.], device='cuda:0'), tensor([1., 1., 0., 0., 0., 0.], device='cuda:0'), tensor([0., 0., 0., 0., 1., 1., 0., 0.], device='cuda:0'), tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 1., 1., 1., 0., 0.], device='cuda:0'), tensor([0., 0., 0., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([0., 0., 0., 0., 1., 1., 1., 1., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 0.], device='cuda:0'), tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 0., 0., 1., 1., 0., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.], device='cuda:0'), tensor([0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.], device='cuda:0'), tensor([0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.], device='cuda:0'), tensor([0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0.], device='cuda:0'), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.], device='cuda:0'), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 1., 0., 0.], device='cuda:0'), tensor([0., 0., 1., 1., 0., 0., 1., 1., 0., 0.], device='cuda:0'), tensor([1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.], device='cuda:0'), tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'), tensor([0., 0., 1., 1., 1., 1., 0., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.], device='cuda:0')] tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
            "        36, 37, 38, 39, 40, 41, 42])\n"
          ]
        }
      ],
      "source": [
        "rosicrucian_cipher_numpy = {key:np.array([int(x) for x in rosicrucian_cipher_dict[key]] + [0, 0])\n",
        "                    for key in rosicrucian_cipher_dict.keys()}\n",
        "\n",
        "subset = list(rosicrucian_cipher_numpy.keys())\n",
        "\n",
        "id2key = subset\n",
        "key2id = {}\n",
        "for idx, s in enumerate(subset):\n",
        "    key2id[s] = idx\n",
        "\n",
        "X = [ttype(rosicrucian_cipher_numpy[k])for k in subset]\n",
        "Y = torch.LongTensor(np.arange(0,len(X)))\n",
        "print(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-03T01:08:07.166363Z",
          "start_time": "2021-05-03T01:08:07.161989Z"
        },
        "id": "7qHW4MiBHRXV"
      },
      "outputs": [],
      "source": [
        "class SITHCon_Classifier(nn.Module):\n",
        "    def __init__(self, out_classes, layer_params,\n",
        "                 act_func=nn.ReLU, batch_norm=False,\n",
        "                 dropout=.2):\n",
        "        super(SITHCon_Classifier, self).__init__()\n",
        "        last_channels = layer_params[-1]['channels']\n",
        "        self.transform_linears = nn.ModuleList([nn.Linear(l['channels'], l['channels'])\n",
        "                                                for l in layer_params])\n",
        "        self.sithcon_layers = nn.ModuleList([SITHCon_Layer(l, act_func) for l in layer_params])\n",
        "        self.to_out = nn.Linear(last_channels, out_classes)\n",
        "\n",
        "\n",
        "    def forward(self, inp):\n",
        "\n",
        "        x = inp\n",
        "        #out = []\n",
        "        for i in range(len(self.sithcon_layers)):\n",
        "            x = self.sithcon_layers[i](x)\n",
        "\n",
        "            x = self.transform_linears[i](x[:,0,:,:].transpose(1,2))\n",
        "            x = x.unsqueeze(1).transpose(2,3)\n",
        "\n",
        "            #out.append(x.clone())\n",
        "        x = x.transpose(2,3)[:, 0, :, :]\n",
        "        #x = x.transpose(2,3)[:, 0, :, :]\n",
        "        x = self.to_out(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBobaK1MHRXW"
      },
      "source": [
        "# Three Layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = [400, 35, 23, 2]\n",
        "\n",
        "sp1 = dict(in_features=1,\n",
        "           tau_min=.1, tau_max=4000, buff_max=6500,\n",
        "           dt=1, ntau=p[0], k=p[1], g=0.0, ttype=ttype,\n",
        "           channels=35, kernel_width=p[2], dilation=p[3],\n",
        "           dropout=None, batch_norm=None)\n",
        "sp2 = dict(in_features=sp1['channels'],\n",
        "           tau_min=.1, tau_max=4000, buff_max=6500,\n",
        "           dt=1, ntau=p[0], k=p[1], g=0.0, ttype=ttype,\n",
        "           channels=35, kernel_width=p[2], dilation=p[3],\n",
        "           dropout=None, batch_norm=None)\n",
        "sp3 = dict(in_features=sp2['channels'],\n",
        "           tau_min=.1, tau_max=4000, buff_max=6500,\n",
        "           dt=1, ntau=p[0], k=p[1], g=0.0, ttype=ttype,\n",
        "           channels=35, kernel_width=p[2], dilation=p[3],\n",
        "           dropout=None, batch_norm=None)\n",
        "\n",
        "# TWO LAYERS\n",
        "layer_params = [sp1, sp2]#, sp3]\n",
        "\n",
        "\n",
        "model = SITHCon_Classifier(len(X), layer_params, act_func=nn.ReLU).cuda()\n",
        "model\n",
        "tot_weights = 0\n",
        "for p in model.parameters():\n",
        "    tot_weights += p.numel()\n",
        "print(\"Total Weights:\", tot_weights)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwPZN53iNKWQ",
        "outputId": "f8f46781-bc32-4840-db3f-d17631f11294"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tau_min': 0.1, 'tau_max': 4000, 'buff_max': 6500, 'dt': 1, 'ntau': 400, 'k': 35, 'g': 0.0, 'ttype': <class 'torch.cuda.FloatTensor'>, 'dropout': None, 'batch_norm': None}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tau_min': 0.1, 'tau_max': 4000, 'buff_max': 6500, 'dt': 1, 'ntau': 400, 'k': 35, 'g': 0.0, 'ttype': <class 'torch.cuda.FloatTensor'>, 'dropout': None, 'batch_norm': None}\n",
            "Total Weights: 33118\n",
            "SITHCon_Classifier(\n",
            "  (transform_linears): ModuleList(\n",
            "    (0-1): 2 x Linear(in_features=35, out_features=35, bias=True)\n",
            "  )\n",
            "  (sithcon_layers): ModuleList(\n",
            "    (0): SITHCon_Layer(\n",
            "      (tctct): _SITHCon_Core(\n",
            "        (sith): iSITH(ntau=400, tau_min=0.1, tau_max=4000, buff_max=6500, dt=1, k=35, g=0.0)\n",
            "        (conv): Conv2d(1, 35, kernel_size=(1, 23), stride=(1, 1), dilation=(1, 2), bias=False)\n",
            "        (maxp): MaxPool1d(kernel_size=356, stride=356, padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (act_func): ReLU()\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): SITHCon_Layer(\n",
            "      (tctct): _SITHCon_Core(\n",
            "        (sith): iSITH(ntau=400, tau_min=0.1, tau_max=4000, buff_max=6500, dt=1, k=35, g=0.0)\n",
            "        (conv): Conv2d(1, 35, kernel_size=(35, 23), stride=(1, 1), dilation=(1, 2), bias=False)\n",
            "        (maxp): MaxPool1d(kernel_size=356, stride=356, padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (act_func): ReLU()\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (to_out): Linear(in_features=35, out_features=43, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "epochs = 5000\n",
        "Trainscale = 10\n",
        "device='cuda'\n",
        "batch_size = 8\n",
        "batches = int(np.ceil(43 / batch_size))\n",
        "progress_bar = tqdm(range(int(epochs)), bar_format='{l_bar}{bar:5}{r_bar}{bar:-5b}')\n",
        "times_100 = 0\n",
        "for epoch_idx in progress_bar:\n",
        "    perfs = []\n",
        "    losses = []\n",
        "    model.train()\n",
        "    for batch_idx in range(batches):\n",
        "        optimizer.zero_grad()\n",
        "        loss = 0\n",
        "        permute = np.arange(0, 43)\n",
        "        for i in range(0, int(min(len(X) - (batch_idx*batch_size),\n",
        "                              batch_size))\n",
        "                       ):\n",
        "            iv = X[permute[batch_idx*batch_size + i]]\n",
        "            iv = iv.unsqueeze(0).unsqueeze(0).unsqueeze(0).to(device)\n",
        "            iv = iv.unsqueeze(-1)\n",
        "            iv = iv.repeat(1,1,1,1,Trainscale)\n",
        "            iv = iv.reshape(1,1,1,-1)\n",
        "            tv = Y[permute[batch_idx*batch_size + i]].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(iv)\n",
        "            loss += loss_func(out[:, -1, :],\n",
        "                             torch.cuda.LongTensor([tv]))\n",
        "            perfs.append((torch.argmax(out[:, -1, :], dim=-1) ==\n",
        "                      tv).sum().item())\n",
        "        loss = loss / min(len(X) - (batch_idx*batch_size),\n",
        "                          batch_size)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        #perfs = perfs[int(-loss_buffer_size/batch_size):]\n",
        "        losses.append(loss.detach().cpu().numpy())\n",
        "        #losses = losses[int(-loss_buffer_size/batch_size):]\n",
        "\n",
        "\n",
        "        s = \"{}:{:2} Loss: {:.4f}, Perf: {:.4f}\"\n",
        "        format_list = [epoch_idx, batch_idx, np.mean(losses),\n",
        "                       np.sum(perfs)/((len(perfs)))]\n",
        "        s = s.format(*format_list)\n",
        "        progress_bar.set_description(s)\n",
        "    if (np.sum(perfs)/((len(perfs))) == 1.0) & (np.mean(losses) < .11):\n",
        "        times_100 += 1\n",
        "        if times_100 >= 3:\n",
        "            break\n",
        "    else:\n",
        "        times_100 = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "c01ac8e4c2954c5fbb3068434268395a",
            "72edf122b8ab4a11b871f17a2744d994",
            "113c09725be347e1a36306287d3524cd",
            "6fc11980e5c945119f18901628fb5b28",
            "cf7dabeeb6ad4d539339eafb1ca86464",
            "8dcae7af11484975bd1983a657dbaf16",
            "ac21f3aaf38b49a5a2795396a2e608dd",
            "4ba116a04edb4e89a2cdbed0dff9c096",
            "d0f1c0c11e2b451fb1c440325f987069",
            "686a05621f614493a444118dbfe2f902",
            "f25a5d77797f45cca3f118b97ebe789b"
          ]
        },
        "id": "ALaoXDaGNtqJ",
        "outputId": "47f63353-3384-4b0f-db82-b40e0ef857f7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|     | 0/5000 [00:00<?, ?it/s]     "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c01ac8e4c2954c5fbb3068434268395a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c6b21f696276>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m#perfs = perfs[int(-loss_buffer_size/batch_size):]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;31m#losses = losses[int(-loss_buffer_size/batch_size):]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSCdia4zHRXa"
      },
      "source": [
        "# TEST\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-03T01:23:29.500713Z",
          "start_time": "2021-05-03T01:23:26.450075Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2_Bzo2UHRXa",
        "outputId": "0265c5e6-63b5-4c6c-a57a-509261d4db2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0.06976744186046512\n",
            "2 0.16279069767441862\n",
            "5 0.6976744186046512\n",
            "6 0.7906976744186046\n",
            "7 0.8372093023255814\n",
            "8 0.8372093023255814\n",
            "9 0.8604651162790697\n",
            "10 0.8604651162790697\n",
            "11 0.8604651162790697\n",
            "12 0.8604651162790697\n",
            "13 0.8372093023255814\n",
            "14 0.8372093023255814\n",
            "15 0.8372093023255814\n",
            "16 0.813953488372093\n",
            "17 0.813953488372093\n",
            "18 0.813953488372093\n",
            "19 0.813953488372093\n",
            "20 0.813953488372093\n",
            "30 0.7906976744186046\n",
            "40 0.7906976744186046\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "evald = []\n",
        "evaldDict = {'perf':[],\n",
        "             'scale':[]}\n",
        "for nr in [1,2,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,30,40]:\n",
        "#for nr in range(1,40,):\n",
        "    perfs = []\n",
        "    for batch_idx, iv in enumerate(X):\n",
        "        iv = iv.unsqueeze(0).unsqueeze(0).unsqueeze(0).to(device)\n",
        "        iv = iv.unsqueeze(-1)\n",
        "        iv = iv.repeat(1,1,1,1,nr)\n",
        "        iv = iv.reshape(1,1,1,-1)\n",
        "        tv = Y[batch_idx].to(device)\n",
        "        out = model(iv)\n",
        "        loss = loss_func(out[:, -1, :],\n",
        "                         torch.cuda.LongTensor([tv]))\n",
        "\n",
        "\n",
        "        perfs.append((torch.argmax(out[:, -1, :], dim=-1) ==\n",
        "                      tv).sum().item())\n",
        "    evaldDict['perf'].append(sum(perfs)/len(perfs))\n",
        "    evaldDict['scale'].append(nr)\n",
        "    print(nr, sum(perfs)/len(perfs))\n",
        "    evald.append([nr, sum(perfs)/(len(perfs)*1.0)])\n",
        "scale_perfs = pd.DataFrame(evaldDict)\n",
        "directory = \"perf\"\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "scale_perfs.to_pickle(join(\"perf\", \"sithcon_rosicrucian_test.dill\"))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c01ac8e4c2954c5fbb3068434268395a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72edf122b8ab4a11b871f17a2744d994",
              "IPY_MODEL_113c09725be347e1a36306287d3524cd",
              "IPY_MODEL_6fc11980e5c945119f18901628fb5b28"
            ],
            "layout": "IPY_MODEL_cf7dabeeb6ad4d539339eafb1ca86464"
          }
        },
        "72edf122b8ab4a11b871f17a2744d994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dcae7af11484975bd1983a657dbaf16",
            "placeholder": "​",
            "style": "IPY_MODEL_ac21f3aaf38b49a5a2795396a2e608dd",
            "value": ""
          }
        },
        "113c09725be347e1a36306287d3524cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ba116a04edb4e89a2cdbed0dff9c096",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0f1c0c11e2b451fb1c440325f987069",
            "value": 2450
          }
        },
        "6fc11980e5c945119f18901628fb5b28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_686a05621f614493a444118dbfe2f902",
            "placeholder": "​",
            "style": "IPY_MODEL_f25a5d77797f45cca3f118b97ebe789b",
            "value": "2450: 0 Loss: 0.3118, Perf: 0.7500:  49%|██▍  | 2450/5000 [18:37&lt;18:56,  2.24it/s]     "
          }
        },
        "cf7dabeeb6ad4d539339eafb1ca86464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dcae7af11484975bd1983a657dbaf16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac21f3aaf38b49a5a2795396a2e608dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ba116a04edb4e89a2cdbed0dff9c096": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0f1c0c11e2b451fb1c440325f987069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "686a05621f614493a444118dbfe2f902": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f25a5d77797f45cca3f118b97ebe789b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}